---
title: Evidence Independence
description: Principle that agreement from shared training bias is not real consensus
---

Evidence independence is the principle that apparent agreement among AI models
does not constitute genuine consensus if the agreement stems from shared
training data rather than independent evidence. Models trained on overlapping
corpora can converge on the same errors, making "consensus" a reflection of bias
rather than truth.

This is a known limitation of the
[Multi-AI Consensus Protocol](./multi-ai-consensus-protocol). The protocol
treats model disagreement as a red flag, but agreement provides only weak
assurance because the models are not independent observers.

True [verification](./verification) requires tracing claims to independent
[sources](./source) and [evidence spans](./evidence-span) outside the training
distribution. The [Operator](./operator) must remain skeptical of AI agreement
and seek external confirmation for high-stakes claims.
