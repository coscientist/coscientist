---
title: Déqualification par délégation à l’IA
description:
  Risque de perte de capacité d’apprentissage lorsque l’IA fait le travail
  cognitif
sourceLocale: en
sourceHash: 4403bb1f64b0
translatedAt: 2026-01-14
---

La déqualification par délégation à l’IA correspond au risque que le fait de
décharger le travail cognitif sur l’IA érode la capacité à effectuer ce travail
sans aide. Si la vérification est toujours automatisée,
l’[Opérateur](./operator) ne s’exerce jamais à vérifier. Si la synthèse est
toujours générée, l’Opérateur n’apprend jamais à synthétiser.

C’est lié à l’[effondrement du modèle](./model-collapse), mais cela se produit
chez l’humain plutôt que dans le modèle : les compétences s’atrophient
lorsqu’elles ne sont pas exercées. La [méta-apprentissage](./meta-learning)
exige de faire l’apprentissage, pas seulement d’en recevoir le résultat.

[Cosscientist](./coscientist) répond à ce problème en traitant l’IA comme un
partenaire pour le [travail de contemplation](./contemplation-labor) plutôt que
comme un remplacement du jugement. L’Opérateur pratique toujours la
[récupération active](./active-recall), retrace des
[segments de preuve](./evidence-span) et s’engage dans la
[contestation](./contention). Le système prend en charge la recherche et la
structuration ; l’humain prend en charge la vérification et la décision.
