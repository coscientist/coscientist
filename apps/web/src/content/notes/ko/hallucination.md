---
title: 환각
description: 그럴듯하지만 사실과 다르거나 조작된 AI 출력
sourceLocale: en
sourceHash: 35a042b51f6a
translatedAt: 2026-01-14
---

환각은 확신에 차고 일관되게 읽히지만 사실 오류, 조작된 정보, 또는 꾸며낸 출처를
포함하는 AI 출력이다. 위험은 무작위성이 아니라 그럴듯함이다. 환각된 텍스트는
진실한 산문의 통계적 패턴을 따르기 때문에, 대충 훑어보는 수준의 검증은 종종
통과한다.

환각은 [대규모 언어 모델](./llm)가 작동하는 방식의 증상이다. 즉, 사실인 다음
토큰이 아니라 그럴 가능성이 높은 다음 토큰을 예측한다. 어떤 주제에 대해 학습
데이터가 희박하거나 상충될 때 모델은 보간하며, 그 결과는 매끄럽게 틀릴 수 있다.
이것이 [유창성 함정](./fluency-trap)이 그토록 위험한 이유다. 유창함은 정확성을
의미하지 않는다.

[Coscientist](./coscientist)에서는
[인식론적 프로토콜 계층](./epistemic-protocol-layer)을 통해 환각 위험을
관리한다. [추적 가능성](./traceability)은 주장들이
[증거 구간](./evidence-span)과 연결되도록 요구하고,
[반박 우선 탐색](./rebuttal-first-search)은 수용 전에 스트레스 테스트를
수행하며, [Multi-AI 합의 프로토콜](./multi-ai-consensus-protocol)은 모델 간
불일치를 더 면밀한 검토가 필요하다는 신호로 사용한다.
