---
title: 训练数据污染
description: AI 生成内容正在污染用于训练未来模型的语料库
sourceLocale: en
sourceHash: a873d340b329
translatedAt: 2026-01-14
---

训练数据污染指的是：AI 生成的文本进入网络，被抓取进训练语料库，并塑造下一代模型。结果是一种反馈回路：在其前代输出上训练出来的模型，会继承其偏见、放大其错误，并失去那种让原始模型有用的、独立的人类信号。

这不同于基准污染（测试数据泄漏进训练集），尽管两者共享“污染”一词。训练数据污染关注的是底层语料的来源（provenance）：一旦 [AI slop](./ai-slop) 与人类书写的文本在规模上混合在一起，区分它们就会变得昂贵甚至不可能。2022 年之后的网络抓取数据越来越可疑。

其后果会叠加放大。[模型崩塌](./model-collapse) 描述了模型在合成数据上训练时的质量退化：分布变窄、稀有模式消失，输出向一个同质化的平均值收敛。[百科全书熔毁](./encyclopedia-meltdown) 描述了当 AI 输出被当作来源引用时出现的知识系统失灵，从而形成循环的权威。训练数据污染是两者的上游成因。

与 [低本底钢](./low-background-steel) 的类比能更清楚地说明问题。核试验污染了所有 1945 年之后的钢铁；LLM 的扩散污染了所有 2020 年之后的网络文本。两次污染事件都不可逆，都催生了对 [污染前资源](./pre-contamination-resource) 的需求，也都意味着：要推进这项技术，就需要使用在该技术出现之前生产的材料。

解决方案包括 [来源](./provenance) 核验、按时间戳门控（timestamp-gated）的档案库，以及优先选择具有人类作者身份清晰链条的数据策划实践。MIT 数据来源倡议（MIT Data Provenance Initiative）及类似努力，旨在为训练数据的来源带来透明度——如果未来模型要避免在自己的倒影上训练，这是必不可少的一步。
