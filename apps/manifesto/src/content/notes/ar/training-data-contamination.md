---
title: تلوّث بيانات التدريب
description: محتوى مولَّد بالذكاء الاصطناعي يلوّث المدوّنات النصية المستخدمة لتدريب النماذج المستقبلية
sourceLocale: en
sourceHash: a873d340b329
translatedAt: 2026-01-14
---

يحدث تلوّث بيانات التدريب عندما يدخل نصّ مولَّد بالذكاء الاصطناعي إلى الويب، ثم يُستخرَج ضمن المدوّنات التدريبية، ويشكّل الجيل التالي من النماذج. والنتيجة حلقة تغذية راجعة: فالنماذج المدرَّبة على مخرجات أسلافها ترث تحيّزاتهم، وتضخّم أخطاءهم، وتفقد الوصول إلى الإشارة البشرية المستقلة التي جعلت النماذج الأصلية مفيدة.

وهذا يختلف عن تلوّث المقاييس المعيارية (تسرّب بيانات الاختبار إلى مجموعات التدريب)، رغم اشتراكهما في المصطلح. فتلوّث بيانات التدريب يتعلّق بمنشأ المدوّنة الأساسية: ما إن يمتزج [هُراء الذكاء الاصطناعي](./ai-slop) مع نصوص كتبها البشر على نطاق واسع، حتى يصبح التمييز بينهما مكلفًا أو مستحيلًا. وأصبحت عمليات استخراج محتوى الويب بعد 2022 أكثر إثارة للشك.

وتتفاقم العواقب. يصف [انهيار النموذج](./model-collapse) تدهور الجودة عندما تُدرَّب النماذج على بيانات اصطناعية: تضيق التوزيعات، وتختفي الأنماط النادرة، ويتقارب الناتج نحو متوسط متجانس. ويصف [انصهار الموسوعة](./encyclopedia-meltdown) فشل منظومة المعرفة عندما تُستشهد مخرجات الذكاء الاصطناعي بوصفها مصادر، بما يخلق سلطة دائرية. وتلوّث بيانات التدريب هو السبب المنبعِي لكليهما.

ويوضح التشابه مع [الفولاذ منخفض الخلفية الإشعاعية](./low-background-steel) المشكلة. فقد لوّثت التجارب النووية كل الفولاذ المُنتَج بعد 1945؛ وجرى تلويث كل نصوص الويب بعد 2020 مع انتشار النماذج اللغوية الكبيرة . وكان كلا الحدثين غير قابل للعكس، وكلاهما خلق طلبًا على [موارد ما قبل التلوّث](./pre-contamination-resource)، وكلاهما يعني أن دفع التكنولوجيا قدمًا يتطلب موادّ أُنتجت قبل وجود التكنولوجيا نفسها.

تشمل الحلول التحقق من [منشأ البيانات](./provenance)، وأرشيفات مقيّدة بالطوابع الزمنية، وممارسات تنقيح بيانات تمنح الأولوية للمصادر ذات سلاسل واضحة من التأليف البشري. وتهدف مبادرة MIT لمنشأ البيانات وجهود مماثلة إلى إضفاء شفافية على أصول بيانات التدريب—وهي خطوة ضرورية إذا كان للنماذج المستقبلية أن تتجنب التدريب على انعكاساتها الذاتية.
