---
title: توهم
description:
  خروجی‌های هوش مصنوعی که محتمل به نظر می‌رسند اما از نظر واقعیت نادرست یا
  ساختگی‌اند
sourceLocale: en
sourceHash: 35a042b51f6a
translatedAt: 2026-01-14
---

توهم خروجیِ هوش مصنوعی است که با اعتمادبه‌نفس و منسجم به نظر می‌رسد، اما شامل
خطاهای واقعی، اطلاعات ساختگی، یا ارجاعاتِ اختراع‌شده است. خطر، تصادفی‌بودن نیست:
«محتمل‌بودن» است. متنِ توهم‌زده اغلب از بررسیِ سطحی جان سالم به در می‌برد، چون
از الگوهای آماریِ نثرِ راست‌نما پیروی می‌کند.

توهم، نشانه‌ای از نحوهٔ کار [مدل‌های زبانی بزرگ](./llm) است: آن‌ها محتمل‌ترین
توکن‌های بعدی را پیش‌بینی می‌کنند، نه توکن‌های درست را. وقتی دادهٔ آموزشی
دربارهٔ یک موضوع کم‌پشت یا متناقض باشد، مدل دست به میان‌یابی می‌زند و نتیجه
می‌تواند به‌نرمی غلط از آب دربیاید. به همین دلیل [تلهٔ روانی](./fluency-trap)
این‌قدر خطرناک است: روانی لزوماً به معنای دقت نیست.

در [پژوهشگر مشترک](./coscientist)، ریسک توهم از طریق
[لایهٔ پروتکل معرفتی](./epistemic-protocol-layer) مدیریت می‌شود:
[قابلیت ردیابی](./traceability) ایجاب می‌کند ادعاها به
[بازه‌های شواهد](./evidence-span) متصل شوند،
[جست‌وجوی ردیه‌محور](./rebuttal-first-search) پیش از پذیرش، ادعاها را تحت آزمونِ
فشار قرار می‌دهد، و [پروتکل اجماع چند-هوش‌مصنوعی](./multi-ai-consensus-protocol)
از اختلاف نظر مدل‌ها به‌عنوان سیگنالی برای بررسی دقیق‌تر استفاده می‌کند.
