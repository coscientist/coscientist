---
title: এলএলএম
description: "বৃহৎ ভাষা মডেল, কসায়েন্টিস্টের contemplation labor-এর অন্তর্নিহিত এআই স্থাপত্য"
sourceLocale: en
sourceHash: a03c9bb62d5e
translatedAt: 2026-01-14
---

LLM বলতে বোঝায় এমন নিউরাল নেটওয়ার্ক মডেল, যেগুলো বিশাল টেক্সট কর্পাসে
প্রশিক্ষিত হয়ে প্রাকৃতিক ভাষার পরবর্তী টোকেন পূর্বানুমান ও ভাষা उत्पादन করে।
উদাহরণ হিসেবে GPT, Claude, Gemini, এবং Llama উল্লেখযোগ্য। প্রশিক্ষণ ডেটা থেকে
পরিসংখ্যানগত ধাঁচ শিখে LLM বিভিন্ন ভাষাগত কাজ করতে পারে—সারসংক্ষেপ, অনুবাদ,
প্রশ্নোত্তর, কোড জেনারেশন ইত্যাদি।

[সহ-বিজ্ঞানী](./coscientist)-এর ক্ষেত্রে, LLM হলো সেই ইঞ্জিন যা
[contemplation labor](./contemplation-labor) সম্পাদন করে: অনুমান প্রস্তাব করা,
প্রমাণ সংগ্রহ করা, পাল্টা উদাহরণ খোঁজা, এবং যুক্তি কাঠামোবদ্ধ করা। যেহেতু LLM যে
কোনো ভাষা পড়তে পারে, তাই
[cross-linguistic synthesis](./cross-linguistic-synthesis) তার একটি স্বাভাবিক
সক্ষমতা হিসেবে সম্ভব হয়।

তবে, LLM-এর মৌলিক সীমাবদ্ধতা আছে। এগুলো সত্যের জন্য নয়, বরং বিশ্বাসযোগ্য
পরবর্তী টোকেনের জন্য অপ্টিমাইজ করে। এগুলো [hallucinate](./hallucination) করতে
পারে: আত্মবিশ্বাসী ও সুসংগত লেখা তৈরি করা যা বাস্তবে তথ্যগতভাবে ভুল। এগুলো
[fluency trap](./fluency-trap)-এর ঝুঁকিতে থাকে: মসৃণ গদ্য যা ভুলকে আড়াল করে।
এগুলো প্রায়ই একই প্রশিক্ষণ ডেটা ভাগাভাগি করে, তাই মডেলগুলোর মধ্যে ঐকমত্য
স্বাধীন [verification](./verification)-এর চেয়ে সম্পর্কিত পক্ষপাত প্রতিফলিত করতে
পারে (দেখুন [evidence independence](./evidence-independence))।

এই কারণেই [সহ-বিজ্ঞানী](./coscientist) LLM-কে ওরাকল নয়, টুল হিসেবে বিবেচনা করে।
[অপারেটর](./operator) সার্বভৌমত্ব ধরে রাখে;
[epistemic protocol layer](./epistemic-protocol-layer)
[traceability](./traceability) এবং
[খণ্ডন-প্রাথমিকতা অনুসন্ধান](./rebuttal-first-search) প্রয়োগ করে; এবং
[Multi-AI Consensus Protocol](./multi-ai-consensus-protocol) মডেলগুলোর মতবিরোধকে
আরও নিবিড় পর্যালোচনার সংকেত হিসেবে ব্যবহার করে। LLM অনুসন্ধান ও কাঠামোবদ্ধকরণ
করে; মানুষ যাচাই ও সিদ্ধান্ত নেয়।
