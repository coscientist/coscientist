---
title: भ्रम
description:
  AI आउटपुट जो विश्वसनीय लगते हैं लेकिन तथ्यात्मक रूप से गलत या गढ़े हुए होते
  हैं
sourceLocale: en
sourceHash: 35a042b51f6a
translatedAt: 2026-01-14
---

भ्रम वह AI आउटपुट है जो आत्मविश्वासी और सुसंगत लगता है, लेकिन उसमें तथ्यात्मक
त्रुटियाँ, गढ़ी हुई जानकारी, या मनगढ़ंत संदर्भ शामिल होते हैं। खतरा यादृच्छिकता
नहीं है: खतरा विश्वसनीयता है। भ्रमित पाठ अक्सर सतही जाँच में सही लग जाता है
क्योंकि वह सत्यनिष्ठ गद्य के सांख्यिकीय पैटर्न का अनुसरण करता है।

भ्रम इस बात का लक्षण है कि [बड़े भाषा मॉडल](./llm) कैसे काम करते हैं: वे सही
टोकन नहीं, बल्कि अगले संभावित टोकन की भविष्यवाणी करते हैं। जब किसी विषय पर
प्रशिक्षण डेटा कम या परस्पर विरोधी होता है, तो मॉडल इंटरपोलेट करता है, और परिणाम
सहज रूप से गलत हो सकता है। यही कारण है कि [fluency trap](./fluency-trap) इतना
खतरनाक है: प्रवाह का अर्थ सटीकता नहीं होता।

[सह-वैज्ञानिक](./coscientist) में, भ्रम का जोखिम
[epistemic protocol layer](./epistemic-protocol-layer) के माध्यम से प्रबंधित
किया जाता है: [traceability](./traceability) के लिए दावों का
[evidence spans](./evidence-span) से जुड़ना आवश्यक है,
[खंडन-पहले खोज](./rebuttal-first-search) स्वीकार करने से पहले स्ट्रेस-टेस्ट करता
है, और [Multi-AI Consensus Protocol](./multi-ai-consensus-protocol) मॉडल असहमति
को अधिक करीबी जाँच के संकेत के रूप में उपयोग करता है।
