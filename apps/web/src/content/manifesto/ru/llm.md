---
title: LLM
description: "Большая языковая модель — архитектура ИИ, лежащая в основе созерцательного труда Coscientist"
sourceLocale: en
sourceHash: a03c9bb62d5e
translatedAt: 2026-01-14
---

LLM — это модели нейронных сетей, обученные на огромных текстовых корпусах для предсказания и генерации естественного языка. Примеры: GPT, Claude, Gemini и Llama. LLM способны выполнять широкий спектр языковых задач — суммаризацию, перевод, ответы на вопросы, генерацию кода — обучаясь статистическим паттернам на данных обучения.

Для [Соисследователь](./coscientist) LLM — это двигатель, выполняющий [созерцательный труд](./contemplation-labor): выдвижение гипотез, сбор свидетельств, поиск контрпримеров и структурирование аргументов. Поскольку LLM могут читать любой язык, они обеспечивают [межъязыковой синтез](./cross-linguistic-synthesis) как встроенную способность.

Однако у LLM есть фундаментальные ограничения. Они оптимизируются под правдоподобные следующие токены, а не под истину. Они могут [галлюцинировать](./hallucination): выдавать уверенный, связный текст, который фактически неверен. Они подвержены [ловушке беглости](./fluency-trap): гладкой прозе, маскирующей ошибки. Они разделяют обучающие данные, поэтому согласие между моделями может отражать коррелированное смещение, а не независимую [верификацию](./verification) (см. [независимость свидетельств](./evidence-independence)).

Поэтому [Соисследователь](./coscientist) рассматривает LLM как инструменты, а не как оракулы. [Оператор](./operator) сохраняет суверенитет; [слой эпистемического протокола](./epistemic-protocol-layer) обеспечивает [прослеживаемость](./traceability) и [поиск с приоритетом опровержений](./rebuttal-first-search); а [Протокол мульти-ИИ консенсуса](./multi-ai-consensus-protocol) использует расхождения между моделями как сигнал к более тщательной проверке. LLM выполняют поиск и структурирование; люди выполняют верификацию и принимают решения.
