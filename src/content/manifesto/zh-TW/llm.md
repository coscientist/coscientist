---
title: LLM
description: 大型語言模型，支撐 Coscientist 進行沉思勞動的 AI 架構
sourceLocale: en
sourceHash: a03c9bb62d5e
translatedAt: 2026-01-14
---

LLM（Large Language
Model）指的是在海量文本語料上訓練的神經網路模型，用於預測並生成自然語言。例子包括 GPT、Claude、Gemini 與 Llama。LLM 能透過從訓練資料中學習統計模式，執行廣泛的語言任務——摘要、翻譯、問答、程式碼生成——等。

對於 [共科學家](./coscientist)
而言，LLM 是執行[沉思勞動](./contemplation-labor)的引擎：提出假設、蒐集證據、尋找反例，以及建構論證。由於 LLM 能讀懂任何語言，它們使[跨語言綜合](./cross-linguistic-synthesis)成為一種原生能力。

然而，LLM 有根本性的限制。它們最佳化的是「下一個 token 的合理性」，而非真實性。它們可能會[幻覺](./hallucination)：產出自信、連貫但事實錯誤的文本。它們也容易落入[流暢性陷阱](./fluency-trap)：以順暢的文筆掩蓋錯誤。它們共享訓練資料，因此模型之間的同意可能反映的是相關偏誤（correlated
bias），而非彼此獨立的[驗證](./verification)（見[證據獨立性](./evidence-independence)）。

這也是為什麼 [共科學家](./coscientist)
將 LLM 視為工具，而非神諭。[操作員](./operator)保留主權；[認識論協定層](./epistemic-protocol-layer)強制[可追溯性](./traceability)與[反駁優先搜尋](./rebuttal-first-search)；而[多 AI 共識協定](./multi-ai-consensus-protocol)則把模型分歧視為需要更仔細檢視的訊號。LLM 負責搜尋與結構化；人類負責驗證與決策。
