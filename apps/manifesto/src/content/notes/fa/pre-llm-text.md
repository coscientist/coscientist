---
title: متنِ پیشا-LLM
description: محتوای نوشته‌شده توسط انسان که پیش از آن‌که مدل‌های زبانی بزرگ وب را آلوده کنند تولید شده است
sourceLocale: en
sourceHash: 45aaafa47592
translatedAt: 2026-01-14
---

متنِ پیشا-LLM محتوایی است که توسط انسان نوشته شده و پیش از آن‌که مدل‌های زبانی بزرگ قادر شوند در مقیاس وسیع نثرِ باورپذیر تولید کنند—تقریباً پیش از ۲۰۲۰—ایجاد شده است. ارزش آن در [خاستگاه](./provenance) تأییدشده نهفته است: بی‌ابهام انسان‌نوشته است، نه مصنوعی، و نه به‌صورت بازگشتی از خروجی‌های هوش مصنوعی مشتق شده است.

قیاس با [فولادِ کم‌پس‌زمینه](./low-background-steel) در گفتمان اخیر صریح است. همان‌طور که آزمایش‌های هسته‌ای همهٔ فولادِ پس از ۱۹۴۵ را با ایزوتوپ‌های رادیواکتیو آلوده کرد، تکثیر LLMها نیز وب را با متنِ مصنوعی—که از نوشتار انسانی تمایزنشدنی است—آلوده کرده است. متنِ پیشا-LLM یک [منبعِ پیشا-آلودگی](./pre-contamination-resource) است: محدود، جایگزین‌ناپذیر، و با ارزشی رو‌به‌افزایش.

موضوع صرفاً نظری نیست، بلکه عملی است. آموزشِ هوش مصنوعی روی متنِ تولیدشده توسط هوش مصنوعی باعث [فروپاشی مدل](./model-collapse) می‌شود: توزیعِ خروجی‌ها باریک می‌شود، مُدهای نادر از بین می‌روند، و کیفیت در نسل‌های پیاپی افت می‌کند. پیکره‌های پاکِ انسان‌نوشته برای پرهیز از این دامِ بازگشتی ضروری‌اند، اما [آلودگی دادهٔ آموزشی](./training-data-contamination) باعث می‌شود گردآوری‌های وب پس از ۲۰۲۰ غیرقابل‌اعتماد باشند. بایگانی‌هایی با مُهر زمانیِ قابل‌راستی‌آزمایی—Internet Archive، مخازن دانشگاهی، اسنپ‌شات‌های Common Crawl پیش از ۲۰۲۰—به منابع اولیه برای آموزش‌های آینده تبدیل می‌شوند.

متنِ پیشا-LLM برای اعتبارِ پژوهش نیز اهمیت دارد. مطالعاتِ زبان انسانی، شناخت، و فرهنگ به پیکره‌هایی نیاز دارند که معلوم باشد بازتابِ تولید انسانی‌اند، نه الگوهای آماریِ آموخته‌شده از مدل‌های پیشین. سیلابِ [لجنِ هوش مصنوعی](./ai-slop) در وب، سطحِ نویز را برای تمام تحلیل‌های پایین‌دستی بالا می‌برد.

طنز ماجرا همانند فولادِ کم‌پس‌زمینه است: پیشرفته‌ترین سامانه‌های هوش مصنوعی به متنی وابسته خواهند بود که پیش از آن تولید شده که هوش مصنوعی آن‌قدر پیشرفته باشد که بتواند بنویسد.
