---
title: モデル崩壊
description: 自身が生成したデータで学習したモデルが劣化する現象
sourceLocale: en
sourceHash: 99c346ca8cef
translatedAt: 2026-01-14
---

モデル崩壊（Model
collapse）とは、モデルがAI生成データの割合が増えるデータで学習されることで起こりうる劣化のことです。時間の経過とともに出力分布は狭まり、まれなモードは消失し、学習信号がモデル自身の生成物（アーティファクト）によって汚染されるため、小さな誤りが増幅されうるようになります。

これは、より広い認識論的圧力としての[AIスロップ](./ai-slop)や、自己言及的なテキストがグラウンドトゥルースとして扱われる[エンサイクロペディア・メルトダウン](./encyclopedia-meltdown)のようなシステムレベルの故障モードとも関連しています。
