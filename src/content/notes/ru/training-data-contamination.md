---
title: Загрязнение обучающих данных
description: Контент, сгенерированный ИИ, загрязняет корпуса, используемые для обучения будущих моделей
sourceLocale: en
sourceHash: a873d340b329
translatedAt: 2026-01-14
---

Загрязнение обучающих данных происходит, когда сгенерированный ИИ текст попадает в сеть, затем выгружается в обучающие корпуса и формирует следующее поколение моделей. В результате возникает петля обратной связи: модели, обученные на выходах своих предшественников, наследуют их предвзятости, усиливают их ошибки и теряют доступ к независимому человеческому сигналу, который делал исходные модели полезными.

Это отличается от загрязнения бенчмарков (попадания тестовых данных в обучающие наборы), хотя в обоих случаях используется одно и то же слово. Загрязнение обучающих данных — про происхождение базового корпуса: как только [ИИ-слизь](./ai-slop) в масштабе смешивается с текстом, написанным людьми, различать их становится дорого или невозможно. Веб-выгрузки после 2022 года вызывают всё больше подозрений.

Последствия накапливаются. [Коллапс модели](./model-collapse) описывает деградацию качества, когда модели обучаются на синтетических данных: распределения сужаются, редкие моды исчезают, а выход сходится к усреднённому, унифицированному среднему. [Плавление энциклопедии](./encyclopedia-meltdown) описывает сбой системы знаний, когда выходы ИИ цитируются как источники, создавая замкнутую (циркулярную) авторитетность. Загрязнение обучающих данных — первопричина для обоих явлений.

Параллель с [низкофоновая сталь](./low-background-steel) проясняет проблему. Ядерные испытания загрязнили всю сталь после 1945 года; распространение LLM (large language models, больших языковых моделей) загрязнило весь веб-текст после 2020 года. Оба события загрязнения были необратимыми, оба создали спрос на [ресурсы до загрязнения](./pre-contamination-resource), и оба означают, что дальнейшее развитие технологии требует материалов, произведённых до появления самой технологии.

Решения включают верификацию [происхождения](./provenance), архивы с ограничением по временным меткам , а также практики курирования данных, отдающие приоритет источникам с чёткими цепочками человеческого авторства. Инициатива MIT Data Provenance Initiative и похожие усилия стремятся повысить прозрачность происхождения обучающих данных — необходимый шаг, если будущие модели должны избежать обучения на собственных отражениях.
