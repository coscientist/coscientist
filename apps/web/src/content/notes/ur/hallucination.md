---
title: ہیلوسینیشن
description: ایسے AI آؤٹ پٹس جو بظاہر قابلِ یقین ہوں مگر حقیقتاً غلط یا من گھڑت ہوں
sourceLocale: en
sourceHash: 35a042b51f6a
translatedAt: 2026-01-14
---

ہیلوسینیشن ایسا AI آؤٹ پٹ ہے جو اعتماد اور ربط کے ساتھ لکھا ہوا محسوس ہوتا ہے،
لیکن اس میں حقائق کی غلطیاں، من گھڑت معلومات، یا ایجاد کردہ حوالہ جات شامل ہوتے
ہیں۔ خطرہ بے ترتیبی نہیں ہے: خطرہ قابلِ یقین ہونا ہے۔ ہیلوسینیٹڈ متن اکثر سرسری
جانچ میں اس لیے بچ جاتا ہے کہ یہ درست نثر کے شماریاتی پیٹرنز کی پیروی کرتا ہے۔

ہیلوسینیشن اس بات کی علامت ہے کہ [LLMs](./llm) کیسے کام کرتے ہیں: وہ اگلے ممکنہ
ٹوکنز کی پیش گوئی کرتے ہیں، سچے ٹوکنز کی نہیں۔ جب کسی موضوع پر تربیتی ڈیٹا کم ہو
یا باہم متضاد ہو، تو ماڈل بیچ کی جگہوں کو بھر کر اندازہ لگاتا ہے ، اور نتیجہ نرم
و رواں مگر غلط ہو سکتا ہے۔ اسی لیے [fluency trap](./fluency-trap) اتنا خطرناک
ہے: روانی درستگی کی ضمانت نہیں دیتی۔

[کوسائنٹسٹ](./coscientist) میں ہیلوسینیشن کے خطرے کو
[epistemic protocol layer](./epistemic-protocol-layer) کے ذریعے سنبھالا جاتا ہے:
[traceability](./traceability) تقاضا کرتی ہے کہ دعوے
[evidence spans](./evidence-span) سے جڑیں،
[تردید اول تلاش](./rebuttal-first-search) قبولیت سے پہلے تنقیدی جانچ کرتی ہے،
اور [Multi-AI Consensus Protocol](./multi-ai-consensus-protocol) ماڈلز کے اختلاف
کو مزید باریک بینی سے جانچ کی علامت کے طور پر استعمال کرتا ہے۔
