---
title: LLM
description: "Grand modèle de langage, l’architecture d’IA sous-jacente au travail de contemplation de Coscientist"
sourceLocale: en
sourceHash: a03c9bb62d5e
translatedAt: 2026-01-14
---

LLM désigne des modèles de réseaux de neurones entraînés sur d’énormes corpus de textes afin de prédire et de générer du langage naturel. Des exemples incluent GPT, Claude, Gemini et Llama. Les LLM peuvent effectuer un large éventail de tâches linguistiques — résumé, traduction, questions-réponses, génération de code — en apprenant des motifs statistiques à partir des données d’entraînement.

Pour [Coscientifique](./coscientist), les LLM sont le moteur qui réalise le [travail de contemplation](./contemplation-labor) : proposer des hypothèses, rassembler des preuves, trouver des contre-exemples et structurer des arguments. Comme les LLM peuvent lire n’importe quelle langue, ils permettent la [synthèse interlinguistique](./cross-linguistic-synthesis) comme capacité native.

Cependant, les LLM ont des limites fondamentales. Ils optimisent des prochains tokens plausibles, pas la vérité. Ils peuvent [halluciner](./hallucination) : produire un texte sûr de lui, cohérent, mais factuellement faux. Ils sont sensibles au [piège de la fluidité](./fluency-trap) : une prose fluide qui masque des erreurs. Ils partagent des données d’entraînement ; ainsi, l’accord entre modèles peut refléter un biais corrélé plutôt qu’une [vérification](./verification) indépendante (voir [l’indépendance des preuves](./evidence-independence)).

C’est pourquoi [Coscientifique](./coscientist) traite les LLM comme des outils, pas comme des oracles. L’[Opérateur](./operator) conserve la souveraineté ; la [couche de protocole épistémique](./epistemic-protocol-layer) impose la [traçabilité](./traceability) et la [recherche d’abord de réfutation](./rebuttal-first-search) ; et le [Protocole de consensus Multi-AI](./multi-ai-consensus-protocol) utilise le désaccord entre modèles comme un signal pour une inspection plus approfondie. Les LLM font la recherche et la structuration ; les humains font la vérification et la décision.
