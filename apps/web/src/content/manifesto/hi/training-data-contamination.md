---
title: प्रशिक्षण डेटा संदूषण
description: भविष्य के मॉडलों को प्रशिक्षित करने के लिए उपयोग किए जाने वाले कॉर्पस को प्रदूषित करती AI-जनित सामग्री
sourceLocale: en
sourceHash: a873d340b329
translatedAt: 2026-01-14
---

प्रशिक्षण डेटा संदूषण तब होता है जब AI-जनित पाठ वेब पर आ जाता है, स्क्रैप होकर प्रशिक्षण कॉर्पस में शामिल हो जाता है, और मॉडलों की अगली पीढ़ी को आकार देता है। नतीजा एक फीडबैक लूप होता है: अपने पूर्ववर्तियों के आउटपुट पर प्रशिक्षित मॉडल उनके पक्षपात विरासत में लेते हैं, उनकी त्रुटियों को बढ़ाते हैं, और उस स्वतंत्र मानवीय संकेत तक पहुँच खो देते हैं जिसने मूल मॉडलों को उपयोगी बनाया था।

यह बेंचमार्क संदूषण (टेस्ट डेटा का प्रशिक्षण सेटों में लीक होना) से अलग है, हालांकि दोनों में “संदूषण” शब्द आता है। प्रशिक्षण डेटा संदूषण अंतर्निहित कॉर्पस की उत्पत्ति के बारे में है: एक बार जब [AI slop](./ai-slop) बड़े पैमाने पर मानव-लिखित पाठ के साथ मिल जाता है, तो उन्हें अलग-अलग पहचानना महंगा या असंभव हो जाता है। 2022 के बाद के वेब स्क्रैप तेजी से संदिग्ध होते जा रहे हैं।

इसके परिणाम चक्रवृद्धि रूप से बढ़ते जाते हैं। [Model collapse](./model-collapse) उस गुणवत्ता-ह्रास का वर्णन करता है जो तब होता है जब मॉडल सिंथेटिक डेटा पर प्रशिक्षित होते हैं: वितरण संकुचित हो जाते हैं, दुर्लभ मोड गायब हो जाते हैं, और आउटपुट एक समरूप औसत की ओर अभिसरित होने लगता है। [Encyclopedia Meltdown](./encyclopedia-meltdown) उस ज्ञान-प्रणाली विफलता का वर्णन करता है जब AI आउटपुट को स्रोत के रूप में उद्धृत किया जाता है, जिससे परिपत्र प्राधिकार बनता है। प्रशिक्षण डेटा संदूषण दोनों का अपस्ट्रीम कारण है।

[low-background steel](./low-background-steel) के साथ समानांतर इस समस्या को स्पष्ट करता है। परमाणु परीक्षणों ने 1945 के बाद के सभी स्टील को संदूषित कर दिया; LLM के प्रसार ने 2020 के बाद के सभी वेब टेक्स्ट को संदूषित कर दिया। दोनों संदूषण घटनाएँ अपरिवर्तनीय थीं, दोनों ने [pre-contamination resources](./pre-contamination-resource) की मांग पैदा की, और दोनों का मतलब यह है कि तकनीक को आगे बढ़ाने के लिए ऐसे सामग्री की जरूरत होती है जो तकनीक के अस्तित्व में आने से पहले उत्पादित की गई हो।

समाधानों में [provenance](./provenance) सत्यापन, टाइमस्टैम्प-गेटेड आर्काइव, और ऐसी डेटा क्यूरेशन प्रथाएँ शामिल हैं जो मानवीय लेखन-श्रेय की स्पष्ट श्रृंखला वाले स्रोतों को प्राथमिकता देती हैं। MIT Data Provenance Initiative और इसी तरह के प्रयास प्रशिक्षण डेटा की उत्पत्ति में पारदर्शिता लाने का लक्ष्य रखते हैं—यह एक आवश्यक कदम है ताकि भविष्य के मॉडल अपनी ही परछाइयों पर प्रशिक्षण लेने से बच सकें।
