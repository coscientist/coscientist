---
title: LLM 之前的文本
description: 大型语言模型污染网络之前由人类撰写的内容
sourceLocale: en
sourceHash: 45aaafa47592
translatedAt: 2026-01-14
---

LLM 之前的文本（Pre-LLM text）是指在人类撰写、且早于大型语言模型能够以规模化方式生成可信散文之前所产生的内容——大致在 2020 年之前。它的价值在于可验证的[来源（provenance）](./provenance)：它明确是人类写作，而非合成内容，也不是从 AI 输出递归衍生而来。

近期讨论中对[低本底钢（low-background steel）](./low-background-steel)的类比是明确的。正如核试验使 1945 年之后的所有钢材都被放射性同位素污染一样，LLM 的扩散也用与人类写作难以区分的合成文本污染了网络。LLM 之前的文本是一种[污染前资源](./pre-contamination-resource)：有限、不可替代，并且愈发珍贵。

风险是现实且具体的。用 AI 生成的文本训练 AI 会导致[模型崩塌（model collapse）](./model-collapse)：输出分布变窄，稀有模式消失，质量在代际迭代中持续退化。为了避免这种递归陷阱，必须使用干净的人类写作语料库，但[训练数据污染](./training-data-contamination)使得 2020 年之后的网络抓取数据变得不可靠。带有可核验时间戳的档案——Internet Archive、学术仓储、2020 年之前的 Common Crawl 快照——将成为未来训练的主要来源。

LLM 之前的文本也关系到研究有效性。对人类语言、认知与文化的研究需要已知能够反映人类产出的语料库，而不是从先前模型学习到的统计模式。充斥网络的[AI 垃圾内容（AI slop）](./ai-slop)抬高了所有下游分析的噪声底。

这种讽刺与低本底钢如出一辙：最先进的 AI 系统将依赖于在 AI 尚不足以写作之前产生的文本。
