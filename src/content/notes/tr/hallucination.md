---
title: Halüsinasyon
description: Makul görünen ama olgusal olarak yanlış veya uydurma olan yapay zekâ çıktıları
sourceLocale: en
sourceHash: 35a042b51f6a
translatedAt: 2026-01-14
---

Halüsinasyon, kendinden emin ve tutarlı görünen ancak olgusal hatalar,
uydurulmuş bilgiler veya icat edilmiş kaynaklar içeren bir yapay zekâ
çıktısıdır. Tehlike rastgelelik değildir: makullük . Halüsinasyonlu metin, doğru
düzyazının istatistiksel örüntülerini izlediği için çoğu zaman yüzeysel
incelemeyi geçer.

Halüsinasyon, [LLM’lerin](./llm) nasıl çalıştığının bir belirtisidir: doğru olan
sonraki token’ları değil, olası olanları tahmin ederler. Bir konuda eğitim
verisi seyrekse veya çelişkiliyse, model arayı doldurur ve sonuç akıcı bir
şekilde yanlış olabilir. Bu yüzden [akıcılık tuzağı](./fluency-trap) bu kadar
tehlikelidir: akıcılık doğruluk anlamına gelmez.

[Eşbilimci](./coscientist) içinde halüsinasyon riski,
[epistemik protokol katmanı](./epistemic-protocol-layer) üzerinden yönetilir:
[izlenebilirlik](./traceability), iddiaların
[kanıt aralıklarına](./evidence-span) bağlanmasını gerektirir;
[önce-çürütme araması](./rebuttal-first-search) kabulden önce dayanıklılık
testleri uygular; ve [Çoklu-YZ Uzlaşı Protokolü](./multi-ai-consensus-protocol),
modeller arası anlaşmazlığı daha yakından inceleme için bir sinyal olarak
kullanır.
