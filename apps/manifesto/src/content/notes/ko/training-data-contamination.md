---
title: 학습 데이터 오염
description: 미래 모델을 학습시키는 데 사용되는 코퍼스를 오염시키는 AI 생성 콘텐츠
sourceLocale: en
sourceHash: a873d340b329
translatedAt: 2026-01-14
---

학습 데이터 오염은 AI가 생성한 텍스트가 웹에 유입되고,
그것이 스크레이핑되어 학습 코퍼스에 들어가며, 다음 세대 모델을 형성할 때 발생한다.
그 결과는 피드백 루프다. 전(前)세대 모델의 출력으로 학습된 모델은 그들의 편향을 물려받고,
오류를 증폭시키며, 원래 모델을 유용하게 만들었던 독립적인 인간 신호에 접근하지 못하게 된다.

이는 벤치마크 오염(테스트 데이터가 학습 세트로 새어 들어가는 것)과는 다르지만,
둘 다 같은 단어를 공유한다. 학습 데이터 오염은 기반 코퍼스의 출처에 관한 문제다.
한번 [AI 슬롭](./ai-slop)이 대규모로 인간이 쓴 텍스트와 섞이면, 둘을 구분하는 일은 비싸지거나 불가능해진다.
2022년 이후의 웹 스크레이프는 점점 더 의심스러워지고 있다.

그 결과는 누적된다. [모델 붕괴](./model-collapse)는 모델이 합성 데이터로 학습할 때 발생하는 품질 저하를 설명한다.
분포는 좁아지고, 희귀 모드는 사라지며, 출력은 균질화된 평균으로 수렴한다.
[백과사전 멜트다운](./encyclopedia-meltdown)은 AI 출력이 출처로 인용되면서 지식 시스템이 실패하는 현상을 설명하는데,
이는 순환적 권위를 만들어낸다. 학습 데이터 오염은 이 둘 모두의 상류 원인이다.

[저방사선 강철](./low-background-steel)과의 평행선이 문제를 분명히 한다.
핵실험은 1945년 이후의 모든 강철을 오염시켰고, LLM(대규모 언어 모델) 확산은 2020년 이후의 모든 웹 텍스트를 오염시켰다.
두 오염 사건 모두 되돌릴 수 없었고, 둘 다 [오염 이전 자원](./pre-contamination-resource)에 대한 수요를 만들어냈으며,
둘 다 기술을 발전시키려면 그 기술이 존재하기 이전에 생산된 재료가 필요하다는 뜻이기도 하다.

해결책에는 [출처](./provenance) 검증, 타임스탬프 기반 접근 제한 아카이브, 그리고 인간 저작의 명확한 계보를 가진 출처를
우선시하는 데이터 큐레이션 관행이 포함된다. MIT 데이터 출처 이니셔티브와 유사한 노력은
학습 데이터 기원의 투명성을 가져오려 한다—미래 모델이 자기 자신의 반영으로 학습하는 일을 피하려면 필요한 단계다.
