---
title: 訓練データ汚染
description: 将来のモデルを訓練するために使われるコーパスを汚染するAI生成コンテンツ
sourceLocale: en
sourceHash: a873d340b329
translatedAt: 2026-01-14
---

訓練データ汚染（Training data contamination）は、AIが生成した文章がウェブに流入し、スクレイピングされて訓練用コーパスに取り込まれ、次世代のモデルの形を作ってしまうことで発生する。結果としてフィードバック・ループが生まれる。すなわち、先行モデルの出力で訓練されたモデルはそのバイアスを継承し、誤りを増幅し、元のモデルを有用にしていた独立した人間由来のシグナルへのアクセスを失っていく。

これはベンチマーク汚染（benchmark contamination：テストデータが訓練セットに漏れ込むこと）とは別物で、同じ「汚染」という言葉を共有しているにすぎない。訓練データ汚染が問題にするのは、基盤となるコーパスの来歴（provenance）である。いったん[AIスロップ](./ai-slop)が大規模に人間の書いたテキストと混ざってしまうと、両者を区別するのは高コストになるか、あるいは不可能になる。2022年以降のウェブスクレイプは、疑わしさが増している。

影響は累積する。[モデル崩壊](./model-collapse)（Model collapse）は、モデルが合成データで訓練されることで起きる品質低下を説明する。分布が狭まり、まれなモードが消え、出力が均質化した平均へと収束していく。[エンサイクロペディア・メルトダウン](./encyclopedia-meltdown)（Encyclopedia Meltdown）は、AIの出力が情報源として引用され、循環する権威を生み出すことで起きる知識システムの破綻を説明する。訓練データ汚染は、その両方の上流の原因である。

[低バックグラウンド鋼](./low-background-steel)（low-background steel）との類比は、この問題を明確にする。核実験は1945年以降のあらゆる鋼を汚染した。LLMの増殖は2020年以降のウェブテキスト全体を汚染した。どちらの汚染事象も不可逆であり、どちらも[汚染前の資源](./pre-contamination-resource)（pre-contamination resources）への需要を生み、そしてどちらも、技術を前進させるには、その技術が存在する前に生産された材料が必要になることを意味している。

解決策には、[来歴](./provenance)（provenance）の検証、タイムスタンプでゲートされたアーカイブ、そして人間の著者性の連鎖が明確なソースを優先するデータ・キュレーションの実践が含まれる。MIT Data Provenance Initiativeや類似の取り組みは、訓練データの起源に透明性をもたらすことを目指している——将来のモデルが自分自身の反映で訓練されるのを避けるために必要な一歩である。
