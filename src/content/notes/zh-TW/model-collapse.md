---
title: 模型崩潰
description: 以自身生成資料訓練的模型之退化
sourceLocale: en
sourceHash: 99c346ca8cef
translatedAt: 2026-01-14
---

模型崩潰（Model
collapse）是指當模型在訓練時使用愈來愈多的 AI 生成資料時，可能出現的一種退化現象。隨著時間推移，輸出分佈會變得更狹窄，罕見模式會消失，而小錯誤可能被放大，因為訓練訊號被模型自身的人工產物（artifacts）所污染。

它與更廣泛的認識論壓力（epistemic
pressure）——[AI 廢料](./ai-slop)——有關，也與系統層級的失效模式相關，例如
[百科全書崩潰](./encyclopedia-meltdown)，在那種情況下，自我指涉的文本被視為基準真相（ground
truth）。
