---
title: "ADR 3: Collaboration Protocol (ProseMirror OT, Step Batching, Conflict Handling)"
---

# ADR 3: Collaboration Protocol (ProseMirror OT, Step Batching, Conflict Handling)

## Context

Multiple users need to **edit the same block or document in real-time**, seeing each other's changes instantly. We require a collaboration protocol that merges concurrent edits reliably. ProseMirror was chosen as the rich-text editing framework, and it comes with a collaboration module based on Operational Transformation (OT) in a centralized fashion. We need to integrate this with our Convex backend. Key challenges include: ordering of changes (to avoid divergent states), network latency differences, and conflict resolution (ensuring changes that happen concurrently are applied in a consistent way for all users). We also want to mitigate the known issue of **high-latency users** suffering from repeated OT rebases (where their changes get rejected and must retry if someone else's edit got in first)[[15]](https://stepwisehq.com/blog/2023-07-25-prosemirror-collab-performance/#:~:text=During%2520sessions%2520with%2520a%2520high,and%2520the%2520client%2520backlogs%2520clear). The protocol design must balance real-time responsiveness with fairness and consistency.

## Decision

**Use ProseMirror's centralized OT-based algorithm for collaborative text editing, enhanced with batched step commits on the server to reduce conflict thrash.** In practice, this means:

- We run a **single source of truth** for each document's state on the Convex backend (the "authority" in OT terms). Clients do not directly sync with each other peer-to-peer; all changes funnel through Convex.
- Clients use the ProseMirror collaboration plugin or our Convex-prosemirror integration. Each client maintains its own local version number of the document. When a user makes an edit, it generates one or more ProseMirror Step objects. The client **optimistically applies** the step locally and sends it to the Convex function (e.g. submitSteps) along with the version number the client based it on.
- The Convex server function receives these steps and checks the version.
- If the steps' base version matches the server's current version for that document, the server accepts them. It increments the document's version and records the steps in the steps table (ADR 2) as committed. Then it broadcasts the steps to all other subscribed clients (Convex's real-time push will notify them).
- If the base version is outdated (another user's steps arrived first), the server will **reject** the incoming steps for now. The client is notified (or will infer, when it pulls the latest changes and sees its own changes not applied) that it must rebase. The client will fetch the new steps it missed (Convex provides getSteps from last seen version) and use ProseMirror to **rebase its unconfirmed steps** on top of the latest document state[[16]](https://marijnhaverbeke.nl/blog/collaborative-editing.html#:~:text=By%2520using%2520a%2520central%2520server,,them,%2520before%2520retrying%2520the%2520push). After rebasing locally (which uses position mapping to adjust the step to the new content[[17]](https://marijnhaverbeke.nl/blog/collaborative-editing.html#:~:text=Position%2520Mapping)), the client resends the step. This loop continues until the step is accepted.
- We plan to implement **step batching** on two levels:
- **Client-side batching:** The client will bundle multiple local steps into one submission if they occur in quick succession. For example, ProseMirror's collab plugin already collects "unconfirmed" steps and can send them as one batch to the server periodically[[18]](https://stepwisehq.com/blog/2023-07-25-prosemirror-collab-performance/#:~:text=ProseMirror,at%2520which%2520point%2520they%2520must). We will ensure this is tuned (e.g., send every 50-100ms or on text input pause) so that we reduce overhead and avoid flooding the server with single-character steps.
- **Server-side commit batching:** In the basic OT model, only one client's changes are accepted for a given document version and others get rejected to rebase, which can starve slow connections[[15]](https://stepwisehq.com/blog/2023-07-25-prosemirror-collab-performance/#:~:text=During%2520sessions%2520with%2520a%2520high,and%2520the%2520client%2520backlogs%2520clear). To improve this, our Convex function will attempt to **merge concurrent submissions** instead of outright rejecting. Specifically, if two sets of steps arrive nearly together on the server (both based on version N), we can choose one as the winner for version N+1, but immediately take the second and transform it against the first (using ProseMirror's step transformation logic) rather than rejecting it. We then apply that transformed second set as version N+2 without a round-trip to the client. In effect, the server can do the rebase for the client and accept both in sequence. This approach aligns with the _commit-based collab_ idea, where the server applies commits in order they arrive and maps other concurrent ones accordingly[[9]](https://stepwisehq.com/blog/2023-07-25-prosemirror-collab-performance/#:~:text=The%2520gist%2520is%2520that%2520we,them%2520back%2520to%2520the%2520clients). It avoids the extra latency of clients having to resend. We will start with simple cases (two edits both inserts in different locations can be accepted back-to-back). In complex conflicts (e.g., both edit exactly the same character), the server may still resort to letting one win and one rebase client-side, to keep logic simpler initially.
- **Conflict handling policy:** By default, if two users edit the same text region, the first edit that reaches the server will be applied; the second edit will be transformed. ProseMirror's OT will ensure no document corruption, but the resulting text might intermix changes. Our policy is last-write-wins for overlapping text insertion/deletion conflicts (since the second writer's change is rebased on a document that includes the first writer's change, it effectively comes after). We do not implement any semantic conflict resolution beyond what OT provides – e.g., we won't try to merge two different words typed at the same spot; the OT result (usually both words with one following the other) stands, and it's up to users to manually clean up if needed. The key is all users see the same result.
- We use **ProseMirror's position mapping** to handle concurrent insert/delete adjustments. For instance, if User A inserts a character at position 5 and concurrently User B deletes characters 10-12, when B's delete is applied after A, the delete positions are remapped (+1 offset) to account for A's insert[[19]](https://marijnhaverbeke.nl/blog/collaborative-editing.html#:~:text=1,front%2520of%2520the%2520change's%2520offset)[[17]](https://marijnhaverbeke.nl/blog/collaborative-editing.html#:~:text=Position%2520Mapping). This ensures consistency.
- **Awareness and locking:** We do not implement hard locks on document regions (no pessimistic locking). However, via presence (ADR 7) we will show if someone else is editing a paragraph, to encourage users to avoid editing exactly the same line. This is purely a UX courtesy; the system itself allows concurrent edits anywhere.
- Our Convex backend will use the **@convex-dev/prosemirror-sync** **component** as a foundation. This component provides server functions for submitting steps and snapshots and handles much of the logic above (including version checks and rebase instructions)[[10]](https://github.com/get-convex/prosemirror-sync#:~:text=,side,%2520enabling%2520easy%2520AI%2520interoperation)[[5]](https://github.com/get-convex/prosemirror-sync#:~:text=const%2520prosemirrorSync%2520=%2520new%2520ProsemirrorSync\(components,//). By using it, we get a proven implementation of ProseMirror's OT algorithm in Convex. We will extend or configure it to add the server-side commit batching described.

## Rationale

We chose ProseMirror's OT-based collaboration because it is a well-established solution that fits our centralized backend model. Key reasons:

- **Centralized OT is simpler and consistent:** Unlike fully distributed OT, a centralized approach is "relatively easy to implement and reason about"[[20]](https://marijnhaverbeke.nl/blog/collaborative-editing.html#:~:text=But%2520you%2520can%2520save%2520oh,their%2520Google%2520Docs%E2%80%94a%2520centralized%2520system). We have a single server ordering events, avoiding the complexities of multi-leader consensus. As Marijn Haverbeke (ProseMirror's author) notes, a central authority allows using a linear history like in version control, with clients rebasing their own changes when needed[[8]](https://marijnhaverbeke.nl/blog/collaborative-editing.html#:~:text=Like%2520OT,%2520ProseMirror%2520uses%2520a,will%2520produce%2520the%2520same%2520document). This yields one definitive sequence of edits, which is exactly what our versioning (ADR 2) stores.
- **Leverages ProseMirror's algorithms:** We avoid reinventing the wheel. ProseMirror provides the transformation logic and the collaborative plugin that manages unconfirmed vs confirmed steps. By aligning with that, we ensure our system benefits from years of testing of those transformations. For example, ProseMirror has robust mappings to keep cursors in place through changes[[17]](https://marijnhaverbeke.nl/blog/collaborative-editing.html#:~:text=Position%2520Mapping), which we will utilize in conflict resolution and presence (so a user's cursor moves appropriately when other text is inserted above).
- **Real-time performance:** OT with immediate local application of changes means users see their own typing without delay, and others' edits as soon as network allows. The overhead is minimal JSON diff (steps) and our data model is optimized for that (small step objects). Convex's WebSocket push will deliver updates promptly to all subscribers.
- **Step batching for fairness:** We address the problem observed in high-contention editing sessions where a user with higher latency can become a "starving artist" with their changes constantly rejected[[15]](https://stepwisehq.com/blog/2023-07-25-prosemirror-collab-performance/#:~:text=During%2520sessions%2520with%2520a%2520high,and%2520the%2520client%2520backlogs%2520clear). By batching, we _reduce the frequency of version mismatches_. If 5 users type at once, rather than 5 separate rapid version increments causing collisions, we effectively coalesce changes either on the client or server. The commit-based enhancement (transforming concurrent commits instead of rejecting) is drawn from research that showed it's possible to avoid many client retries and thereby improve throughput[[21]](https://stepwisehq.com/blog/2023-07-25-prosemirror-collab-performance/#:~:text=There%2520are%2520a%2520number%2520of,a%2520lot%2520of%2520extra%2520complexity)[[22]](https://stepwisehq.com/blog/2023-07-25-prosemirror-collab-performance/#:~:text=Can%2520we%2520eliminate%2520the%2520need,work%2520closer%2520to%2520the%2520database). This rationale is to improve _user experience under load_: fewer "your changes were overwritten, retrying…" glitches.
- **Alternatives seen as riskier for MVP:** We considered CRDT (like Yjs) but OT was deemed sufficient and simpler given the client-server architecture. Also, ProseMirror's built-in OT means we didn't need to integrate a new library or change data structures drastically.
- **Convex integration:** The existence of the Convex ProseMirror sync component[[10]](https://github.com/get-convex/prosemirror-sync#:~:text=,side,%2520enabling%2520easy%2520AI%2520interoperation) significantly de-risks this approach. It gives us an out-of-the-box implementation of server-side OT (with functions for submitting steps, fetching steps, handling snapshots) that we can use and then tweak for our needs. This alignment speeds development and ensures correctness, as opposed to writing our own collaboration engine from scratch.

## Alternatives Considered

- **CRDT (Conflict-free Replicated Data Types):** Using a CRDT-based editor (like TipTap with Y.js or similar) was a strong alternative. CRDTs allow true peer-to-peer collaboration and offline edits merging without a central server ordering. However, integrating CRDT in ProseMirror (there is a Y.js plugin for ProseMirror) would introduce heavy data overhead (each character insertion carries an identifier, etc.) and complexity in our storage. Also, real-time OT is already solved by ProseMirror for our use case. We decided to stick with OT now and possibly switch to CRDT if offline capabilities are needed later. Notably, the Convex team suggests a Yjs-specific component could be separate[[14]](https://github.com/get-convex/prosemirror-sync#:~:text=,and%2520doesn't%2520have%2520local%2520changes), implying that mixing OT and CRDT would be non-trivial.
- **Pessimistic Locking:** We could lock a block or section while a user is editing it, to avoid conflicts entirely. This was rejected because it severely hampers collaboration – users would have to wait turns or break documents into tiny locked sections. It doesn't match the freeform concurrent editing experience we want.
- **Third-party collab services:** There are services like Firebase OT, ShareDB, or even using something like Automerge with a central relay. Adopting those would either require replacing ProseMirror's editing behavior or bridging to it. Since ProseMirror already solved this within its ecosystem, adding another layer felt unnecessary.
- **Do Nothing Special (last write wins):** In theory we could let Convex handle concurrent writes by last-write-wins (the last update to a field wins) without OT. This would be disastrous for text merging (lost updates, jumbled text) and is not a real solution for simultaneous editing, so it was not seriously considered.

## Implications

- **Server Load:** Every keystroke potentially results in a Convex function call and database writes (steps). For large collaborative sessions, this can be heavy. We mitigate this with client-side batching (fewer, larger step submissions) and by keeping steps small. Convex's scalability will be tested; however, Convex is designed for real-time updates and can handle many small writes with its **WebSocket reactivity and caching**[[23]](https://stack.convex.dev/presence-with-convex#:~:text=Convex%2520helped%2520make%2520this%2520much,WebSocket%2520reactivity%2520and%2520caching%2520scalability)[[24]](https://stack.convex.dev/presence-with-convex#:~:text=Caching). We will monitor performance, and we might need to tune batch sizes or use Convex's single-flight mechanism to drop intermediate state updates if flooding occurs (similar to presence, see ADR 7).
- **Complexity in Edge Cases:** While ProseMirror OT covers most editing scenarios, certain edge cases like _simultaneous step submission and snapshot submission_ could occur. The convex component has logic to handle snapshot submission concurrency (only last editor triggers snapshot)[[11]](https://github.com/get-convex/prosemirror-sync#:~:text=Configuring%2520the%2520snapshot%2520debounce%2520interval)[[25]](https://github.com/get-convex/prosemirror-sync#:~:text=There%2520can%2520be%2520races,%2520but,and%2520are%2520safe%2520to%2520apply). We need to ensure our usage is correct to avoid race conditions (e.g., two users both think they're last to edit and send snapshots – one will win, the other should be discarded safely).
- **Data Consistency:** We must be careful that the Convex functions that modify documents (applying steps) are **atomic** per document. Convex functions run isolated, so if two calls happen at once on the same doc, one will naturally serialize after the other (Convex ensures consistency in its transaction model). But if we introduce custom logic for merging steps on the server, we have to implement it in that single function call to maintain atomicity. It complicates the server function a bit (it might have to handle an array of step sets).
- **Client Complexity:** Clients need to maintain two sets of state: the optimistic local state and the confirmed server state. This is handled by the ProseMirror collab plugin, but developers must be careful to initialize editors with the correct starting document (from latest snapshot + steps). There is also complexity in error handling – if a client falls far behind (maybe missed many updates), it should reload the document state from scratch. We will likely implement a safety where if a client's version is too old (server doesn't have those old steps anymore), we send them a fresh snapshot to resync.
- **Potential Merge Artifacts:** The OT algorithm doesn't attempt to semantically merge content. So, documents might end up with odd artifacts, like both users typed the same word -> after merge the word appears twice. Or both deleted a line -> after merge, one delete might target text that's already gone, resulting in a no-op for the second (so one deletion "wins" but effectively both wanted to delete, which is fine). These artifacts are generally minor and can be edited out by the users. We will document this known behavior in internal notes so it's understood that the system ensures consistency but not intelligent merging. This is similar to how Google Docs works – simultaneous edits yield a combined result, which users may adjust if needed.
- **Integration with Non-Text Blocks:** Collaboration protocol so far is described for rich-text content (ProseMirror docs). For other block types (images, attachments), "editing" might mean something else (e.g., changing an image's caption or moving it). Those operations might not use ProseMirror at all. We will handle them with simpler strategies: e.g., if two users try to edit an image block's metadata concurrently, the last write might simply win, since such edits are rare and typically not simultaneous. The ADR 3 protocol primarily covers the heavy case of text editing. We will note that any non-text collaborative actions (like two users reordering blocks at the same time) need thought – possibly we treat those also as operations (e.g., an operation to move block X after block Y, which we could sequence similarly).

## Expansion Path

- **True Offline Collaboration:** To support offline work, we might integrate a CRDT-based approach like Yjs. In that scenario, each client could make changes without the server and later merge. We'd need to reconcile that with our current OT log. Possibly, we could run a Yjs document in parallel that syncs to Convex. Alternatively, switch fully to Yjs: the Convex backend could store Yjs updates (deltas) and broadcast them. This would remove the need for central OT and allow federated editing, but we'd have to migrate data structures (ProseMirror content to Yjs format). This is a non-trivial change, but if the product requires offline use or multi-master (federation) editing, it might be necessary.
- **Federated Servers and Consensus:** If in future the knowledge base is distributed across servers (no single authoritative server), we could explore using a consensus algorithm (like Raft or CRDTs) to maintain a consistent ordering of operations across sites[[26]](https://marijnhaverbeke.nl/blog/collaborative-editing.html#:~:text=And%2520I%2520don't%2520actually%2520believe,have%2520not%2520actually%2520tried%2520this). For example, a primary Convex node could be elected among a cluster to order the steps, or use operational transform in a federated setting by having one "arbiter" site. This is complex and likely beyond near-term needs, but the ADR notes it for completeness. Our current design keeps one authority per document (the Convex deployment owning it).
- **Intelligent Merge Assistance:** We could introduce an AI assistant to help with conflict resolution. For instance, if two users edit the same sentence differently, an AI could detect this and suggest a merged version or alert the users. This would layer on top of our existing protocol (the data is there to see the two divergent edits). This could be part of an "AI co-editor" feature implemented via Mastra agents (ADR 8).
- **Scale to High User Counts:** Currently, ProseMirror is optimized for maybe dozens of concurrent users editing a single document. If we ever have a scenario of hundreds collaborating (like a massive shared notepad), we may need to adjust. Step batching becomes crucial, and perhaps limiting update frequency. We might implement a token-bucket or turn-taking at the application level if things get too chaotic. Another optimization could be **region locking on demand** – not mandatory, but if a document is very busy, the system might automatically partition it (for example, lock down a paragraph if too many people try to edit it simultaneously, asking them to queue edits). These are speculative and only if we hit scale issues.
- **Multi-cursor / Multi-region Editing:** ProseMirror by default operates on one document. In a complex scenario, say an outliner with many blocks, perhaps multiple blocks could be edited independently at the same time (since each block is separate content). We plan to treat each top-level document block as separate collab sessions. In expansion, we could have multiple simultaneous OT sessions (one per block being actively edited). Our protocol can handle that by isolating steps per document/block. We just need to ensure consistency if an operation spans blocks (which currently doesn't happen in MVP – each operation is within one block's content).
- **Integration of Comments or Suggestions:** Collaboration isn't just direct edits. We may later add a feature for suggestions (track changes) or inline comments. These add another dimension to collab. We'd extend our model by treating comments as data attached to ranges in the text. We'd then need to ensure that as text changes, comments move accordingly – ProseMirror's mapping can help with that, similar to how it keeps cursor positions stable[[17]](https://marijnhaverbeke.nl/blog/collaborative-editing.html#:~:text=Position%2520Mapping). This likely means storing comments in a structure that references document positions that get updated via step maps on each edit. It's an advanced expansion, but our underlying collab engine would support it since we can map positions through changes reliably.
