---
title: 前 LLM 時代文本
description: 大型語言模型污染網路之前，由人類撰寫的內容
sourceLocale: en
sourceHash: 45aaafa47592
translatedAt: 2026-01-14
---

前 LLM 時代文本是指在大型語言模型尚未具備大規模生成可信散文能力之前——約在 2020 年以前——由人類創作的內容。其價值在於可驗證的[來源（provenance）](./provenance)：它毫無疑義是人類書寫的，而非合成內容，也不是從 AI 輸出遞迴衍生而來。

在近期討論中，與[低背景鋼（low-background steel）](./low-background-steel)的類比被明確提出。正如核試驗使所有 1945 年後的鋼材都受到放射性同位素污染，LLM 的普及也以難以區分於人類書寫的合成文本污染了整個網路。前 LLM 時代文本是一種[污染前資源](./pre-contamination-resource)：有限、不可替代，而且愈發珍貴。

其利害關係是務實且直接的。用 AI 生成文本訓練 AI 會導致[模型崩壞（model collapse）](./model-collapse)：輸出分佈變窄、罕見模式消失，且品質在世代迭代中持續劣化。乾淨的人類書寫語料對避免這種遞迴陷阱至關重要，但[訓練資料污染](./training-data-contamination)使得 2020 年後的網路爬取資料不再可靠。具可驗證時間戳的檔案庫——Internet Archive、學術存儲庫、2020 年前的 Common Crawl 快照——因此成為未來訓練的主要來源。

前 LLM 時代文本也關乎研究的有效性。對人類語言、認知與文化的研究，需要能確定反映人類產出的語料庫，而不是從先前模型學到的統計模式。席捲網路的[AI 廢文（AI slop）](./ai-slop)抬高了所有下游分析的噪音底線。

其諷刺之處與低背景鋼如出一轍：最先進的 AI 系統，將仰賴在 AI 尚不夠先進、無法寫作之前產生的文本。
