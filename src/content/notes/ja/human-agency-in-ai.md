---
title: AIにおける人間のエージェンシー
description: AI支援の知的業務において、人間が主導権を保つための原則とメカニズム
sourceLocale: en
sourceHash: 18286ece9376
translatedAt: 2026-01-14
---

[AI](./ai)における人間のエージェンシー（Human
Agency）とは、AIが相当量の[熟考労働](./contemplation-labor)を担う場合でも、人間の[オペレーター](./operator)が知的業務の主導権を握り続けるための原則とメカニズムのまとまりである。

## 中核原則

- [認知的主権](./cognitive-sovereignty) — 判断と検証に対する人間の統制
- [認知エージェンシーの保全](./cognitive-agency-preservation) —
  AIは判断を強化し、置き換えない
- [オペレーター](./operator) — 主権的な検証者としての人間の役割

## メカニズム

- [責任ライン](./responsibility-line) — 誰が何を主張したかを追跡する
- [検証](./verification) — 受け身の受容ではなく、能動的な確認
- [検証における望ましい困難さ](./desirable-difficulty-in-verification)
  — 関与を保つため、検証をあえて労力の要るものにする

## リスク

- [流暢性の罠](./fluency-trap) — 滑らかな出力を精査なしに受け入れてしまう
- [AI委任によるスキル低下](./deskilling-through-ai-delegation)
  — 使わないことで技能が衰える
- [AIによって誘発される有能感の錯覚](./ai-induced-illusions-of-competence) —
  AI支援による偽の習熟感
