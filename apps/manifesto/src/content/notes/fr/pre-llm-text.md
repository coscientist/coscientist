---
title: Texte pré-LLM
description: Contenu rédigé par des humains, produit avant que les grands modèles de langage ne contaminent le web
sourceLocale: en
sourceHash: 45aaafa47592
translatedAt: 2026-01-14
---

Le texte pré-LLM est du contenu rédigé par des humains, créé avant que les grands modèles de langage ne deviennent capables de générer, à grande échelle, une prose plausible — grosso modo avant 2020. Sa valeur réside dans une [provenance](./provenance) vérifiée : il est sans ambiguïté écrit par des humains, non synthétique, et non dérivé récursivement de sorties d’IA.

L’analogie avec l’[acier à faible bruit de fond](./low-background-steel) est explicite dans les discussions récentes. De même que les essais nucléaires ont contaminé tout l’acier post-1945 avec des isotopes radioactifs, la prolifération des LLM a contaminé le web avec du texte synthétique indiscernable de l’écriture humaine. Le texte pré-LLM est une [ressource pré-contamination](./pre-contamination-resource) : finie, irremplaçable et de plus en plus précieuse.

Les enjeux sont pratiques. Entraîner une IA sur du texte généré par l’IA provoque un [effondrement du modèle](./model-collapse) : les distributions de sortie se resserrent, les modes rares disparaissent et la qualité se dégrade au fil des générations. Des corpus propres, rédigés par des humains, sont essentiels pour éviter ce piège récursif, mais la [contamination des données d’entraînement](./training-data-contamination) rend les collectes web post-2020 peu fiables. Les archives avec des horodatages vérifiables — l’Internet Archive, les dépôts académiques, les instantanés de Common Crawl d’avant 2020 — deviennent des sources primaires pour l’entraînement futur.

Le texte pré-LLM compte aussi pour la validité de la recherche. Les études sur le langage humain, la cognition et la culture exigent des corpus dont on sait qu’ils reflètent une production humaine, et non des motifs statistiques appris à partir de modèles antérieurs. L’[AI slop](./ai-slop) qui inonde le web relève le seuil de bruit pour toutes les analyses en aval.

L’ironie fait écho à celle de l’acier à faible bruit de fond : les systèmes d’IA les plus avancés dépendront de textes produits avant que l’IA ne soit suffisamment avancée pour écrire.
