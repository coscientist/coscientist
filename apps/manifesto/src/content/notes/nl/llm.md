---
title: LLM
description: Large Language Model, de AI-architectuur die het contemplatiewerk van Coscientist ondersteunt
---

LLM (Large Language Model) verwijst naar neurale netwerkmodellen die zijn getraind op enorme tekstcorpora om natuurlijke taal te voorspellen en te genereren. Voorbeelden zijn GPT, Claude, Gemini en Llama. LLM’s kunnen een breed scala aan taaltaken uitvoeren—samenvatten, vertalen, vraag-antwoord, codegeneratie—door statistische patronen uit trainingsdata te leren.

Voor [Coscientist](./coscientist) zijn LLM’s de motor die [contemplatiewerk](./contemplation-labor) uitvoert: hypothesen voorstellen, bewijs verzamelen, tegenvoorbeelden vinden en argumenten structureren. Omdat LLM’s elke taal kunnen lezen, maken ze [cross-linguïstische synthese](./cross-linguistic-synthesis) mogelijk als een ingebouwde vaardigheid.

LLM’s hebben echter fundamentele beperkingen. Ze optimaliseren voor plausibele volgende tokens, niet voor waarheid. Ze kunnen [hallucineren](./hallucination): zelfverzekerde, coherente tekst produceren die feitelijk onjuist is. Ze zijn vatbaar voor de [vloeiendheidsval](./fluency-trap): soepele proza die fouten maskeert. Ze delen trainingsdata, dus overeenstemming tussen modellen kan gecorreleerde vertekening weerspiegelen in plaats van onafhankelijke [verificatie](./verification) (zie [onafhankelijkheid van bewijs](./evidence-independence)).

Daarom behandelt [Coscientist](./coscientist) LLM’s als hulpmiddelen, niet als orakels. De [Operator](./operator) behoudt soevereiniteit; de [epistemische protocollaag](./epistemic-protocol-layer) dwingt [traceerbaarheid](./traceability) en [weerlegging-eerst zoeken](./rebuttal-first-search) af; en het [Multi-AI Consensus Protocol](./multi-ai-consensus-protocol) gebruikt meningsverschil tussen modellen als signaal voor nadere inspectie. LLM’s doen het zoek- en structureerwerk; mensen doen de verificatie en nemen de beslissing.