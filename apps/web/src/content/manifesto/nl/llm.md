---
title: LLM
description:
  "Large Language Model, de AI-architectuur die het contemplatiewerk van
  Coscientist ondersteunt"
sourceLocale: en
sourceHash: a03c9bb62d5e
translatedAt: 2026-01-14
---

LLM verwijst naar neurale netwerkmodellen die zijn getraind op enorme
tekstcorpora om natuurlijke taal te voorspellen en te genereren. Voorbeelden
zijn GPT, Claude, Gemini en Llama. LLM’s kunnen een breed scala aan taaltaken
uitvoeren—samenvatten, vertalen, vraag-antwoord, codegeneratie—door statistische
patronen uit trainingsdata te leren.

Voor [Cowetenschapper](./coscientist) zijn LLM’s de motor die
[contemplatiewerk](./contemplation-labor) uitvoert: hypothesen voorstellen,
bewijs verzamelen, tegenvoorbeelden vinden en argumenten structureren. Omdat
LLM’s elke taal kunnen lezen, maken ze
[cross-linguïstische synthese](./cross-linguistic-synthesis) mogelijk als een
inbegrepen vaardigheid.

LLM’s hebben echter fundamentele beperkingen. Ze optimaliseren voor plausibele
volgende tokens, niet voor waarheid. Ze kunnen [hallucineren](./hallucination):
zelfverzekerde, coherente tekst produceren die feitelijk onjuist is. Ze zijn
vatbaar voor de [vloeiendheidsval](./fluency-trap): soepele proza die fouten
maskeert. Ze delen trainingsdata, dus overeenstemming tussen modellen kan
gecorreleerde vertekening weerspiegelen in plaats van onafhankelijke
[verificatie](./verification).

Daarom behandelt [Cowetenschapper](./coscientist) LLM’s als hulpmiddelen, niet
als orakels. De [Operator](./operator) behoudt soevereiniteit; de
[epistemische protocollaag](./epistemic-protocol-layer) dwingt
[traceerbaarheid](./traceability) en
[weerlegging-eerst zoeken](./rebuttal-first-search) af; en het
[Multi-AI Consensus Protocol](./multi-ai-consensus-protocol) gebruikt
meningsverschil tussen modellen als signaal voor nadere inspectie. LLM’s doen
het zoek- en structureerwerk; mensen doen de verificatie en nemen de beslissing.
