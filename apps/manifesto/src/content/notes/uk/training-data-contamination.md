---
title: Забруднення навчальних даних
description: Контент, згенерований ШІ, забруднює корпуси, що використовуються для навчання майбутніх моделей
sourceLocale: en
sourceHash: a873d340b329
translatedAt: 2026-01-14
---

Забруднення навчальних даних виникає тоді, коли згенерований ШІ текст потрапляє в інтернет, його зішкрібають в навчальні корпуси, і він формує наступне покоління моделей. Результат — петля зворотного зв’язку: моделі, натреновані на виходах своїх попередників, успадковують їхні упередження, підсилюють їхні помилки та втрачають доступ до незалежного людського сигналу, який робив оригінали корисними.

Це відрізняється від забруднення бенчмарків (витоку тестових даних у навчальні набори), хоча в обох випадках використовується слово «забруднення». Забруднення навчальних даних стосується походження базового корпусу: щойно [AI slop](./ai-slop) у великих масштабах змішується з текстами, написаними людьми, відрізнити їх стає дорого або неможливо. Веб-зіскрібки після 2022 року дедалі частіше викликають підозру.

Наслідки накопичуються. [Колапс моделі](./model-collapse) описує деградацію якості, коли моделі навчаються на синтетичних даних: розподіли звужуються, рідкісні моди зникають, а вихід збігається до уніфікованого середнього. [Енциклопедичний мелтдаун](./encyclopedia-meltdown) описує збій системи знань, коли виходи ШІ цитуються як джерела, створюючи замкнену, циркулярну авторитетність. Забруднення навчальних даних є першопричиною обох.

Паралель із [низькофоновою сталлю](./low-background-steel) прояснює проблему. Ядерні випробування забруднили всю сталь після 1945 року; поширення LLM забруднило весь вебтекст після 2020 року. Обидві події забруднення були незворотними, обидві створили попит на [ресурси до забруднення](./pre-contamination-resource), і обидві означають, що просування технології потребує матеріалів, вироблених до появи цієї технології.

Рішення включають перевірку [походження](./provenance), архіви з доступом, обмеженим часовими мітками, та практики курування даних, що надають перевагу джерелам із чіткими ланцюжками людського авторства. Ініціатива MIT Data Provenance Initiative та подібні зусилля прагнуть зробити походження навчальних даних прозорішим — необхідний крок, якщо майбутні моделі мають уникнути навчання на власних віддзеркаленнях.
